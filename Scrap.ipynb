{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pycxsimulator\n",
    "import itertools\n",
    "import dill\n",
    "\n",
    "grid_lw = 32\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, tolerance_threshold: float) -> None:\n",
    "        self.color = np.random.choice([0,1])\n",
    "        self.tolerance_threshold = tolerance_threshold\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self) -> None:\n",
    "        self.graph = nx.Graph()\n",
    "        self.parameters = []\n",
    "        self.attribute_assortativity = []\n",
    "        self.n_connected_components = []\n",
    "        self.avg_cc_size = []\n",
    "        self.std_cc_size = []        \n",
    "\n",
    "def payoff(node, target):\n",
    "    global G, assortativity\n",
    "    x = 0 ### local similarity\n",
    "    occupied_neighbors = 0\n",
    "    similar_neighbors = 0\n",
    "    tolerance_threshold = G.nodes[node]['object'].tolerance_threshold\n",
    "    score = 0\n",
    "    for nbr in G.neighbors(target):\n",
    "        if G.nodes[nbr]['object'] != None:\n",
    "            if G.nodes[nbr]['object'].color == G.nodes[node]['object'].color:\n",
    "                similar_neighbors += 1\n",
    "            occupied_neighbors += 1\n",
    "    if occupied_neighbors > 0:\n",
    "        x = similar_neighbors / occupied_neighbors\n",
    "    else:\n",
    "        x = 1\n",
    "    if (1-x) <= tolerance_threshold:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def non_guttman_transfer_probabilities(node, candidate_vacancies):\n",
    "    global G\n",
    "    transfer_probabilities = []\n",
    "    d = 0\n",
    "    for v in candidate_vacancies:\n",
    "        similar_neighbors = 0\n",
    "        occupied_neighbors = 0\n",
    "        for nbr in G.neighbors(v):\n",
    "            if G.nodes[nbr]['object'] != None:\n",
    "                if G.nodes[nbr]['object'].color == G.nodes[node]['object'].color:\n",
    "                    similar_neighbors += 1\n",
    "            occupied_neighbors += 1\n",
    "        if occupied_neighbors > 0:\n",
    "            x = similar_neighbors / occupied_neighbors\n",
    "        else:\n",
    "            x = 1\n",
    "        d += np.exp(13*x - 17.9*x**2)\n",
    "        transfer_probabilities.append(np.exp(13*x - 17.9*x**2))\n",
    "    transfer_probabilities = [p / d for p in transfer_probabilities]\n",
    "    return transfer_probabilities\n",
    "\n",
    "def set_tolerance_threshold(method='xie_zhou'):\n",
    "    if method == 'xie_zhou':\n",
    "        group = np.random.random()\n",
    "        if group < .1047:\n",
    "            tolerance_threshold = np.random.uniform(0.0,0.07)\n",
    "        elif group < (.1047 + .1810):\n",
    "            tolerance_threshold = np.random.uniform(0.07,0.21)\n",
    "        elif group < (.1047 + .1810 + .2673):\n",
    "            tolerance_threshold = np.random.uniform(0.21,0.36)\n",
    "        elif group < (.1047 + .1810 + .2673 + .1386):\n",
    "            tolerance_threshold = np.random.uniform(0.36,0.57)\n",
    "        elif group < (.1047 + .1810 + .2673 + .1386 + .2659):\n",
    "            tolerance_threshold = np.random.uniform(0.57,1.01)\n",
    "        else:\n",
    "            tolerance_threshold = None\n",
    "        \n",
    "    elif method == 'schelling':\n",
    "        tolerance_threshold = .39604933366910855\n",
    "    \n",
    "    return tolerance_threshold\n",
    "\n",
    "def calculate_mixing():\n",
    "    global G\n",
    "    subgraph_nodes = []\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['object'] != None:\n",
    "            subgraph_nodes.append(node)\n",
    "    subgraph = nx.subgraph(G,subgraph_nodes)\n",
    "    connected_components = list(nx.connected_components(subgraph))\n",
    "    total_size = 0\n",
    "    weighted_assortativity = 0\n",
    "    for c in connected_components:\n",
    "        component_size = len(list(c))\n",
    "        total_size += component_size\n",
    "        component_graph = nx.subgraph(G,list(c))\n",
    "        if len(set([component_graph.nodes[c]['color'] for c in list(component_graph.nodes)])) == 1:\n",
    "            weighted_assortativity += 1 * component_size\n",
    "        else:\n",
    "            weighted_assortativity += (nx.attribute_assortativity_coefficient(component_graph,'color') * component_size)\n",
    "    graph_assortativity_coefficient = weighted_assortativity / total_size\n",
    "    number_of_connected_components = len(list(connected_components))\n",
    "    average_component_size = np.mean([len(c) for c in list(connected_components)])\n",
    "    std_component_size = np.std([len(c) for c in list(connected_components)])\n",
    "    return [graph_assortativity_coefficient, number_of_connected_components, average_component_size, std_component_size]\n",
    "\n",
    "def update_result():\n",
    "    global result\n",
    "    mixing_metrics = calculate_mixing()\n",
    "    result.attribute_assortativity.append(mixing_metrics[0])\n",
    "    result.n_connected_components.append(mixing_metrics[1])\n",
    "    result.avg_cc_size.append(mixing_metrics[2])\n",
    "    result.std_cc_size.append(mixing_metrics[3])\n",
    "\n",
    "\n",
    "def initialize(excess_housing = 0.15, topology_modifier = 128, method='xie_zhou'):\n",
    "    global G, assortativity, pos, vacancies, xz_results, sch_results\n",
    "    G = nx.grid_2d_graph(grid_lw,grid_lw, periodic=False)\n",
    "    pos = dict((n,n) for n in G.nodes)\n",
    "    assortativity = []\n",
    "    vacancies = []\n",
    "    if excess_housing > 0:\n",
    "        for node in G.nodes:\n",
    "            if np.random.random() < excess_housing:\n",
    "                G.nodes[node]['object'] = None\n",
    "                G.nodes[node]['color'] = 2\n",
    "                vacancies.append(node)\n",
    "            else:\n",
    "                G.nodes[node]['object'] = Person(tolerance_threshold=set_tolerance_threshold(method))\n",
    "                G.nodes[node]['color'] = G.nodes[node]['object'].color\n",
    "    else:\n",
    "        for node in G.nodes:\n",
    "            G.nodes[node]['object'] = Person(tolerance_threshold=set_tolerance_threshold(method))\n",
    "            G.nodes[node]['color'] = G.nodes[node]['object'].color\n",
    "    if topology_modifier > 0:\n",
    "        oG = G.copy()\n",
    "        for _ in range(topology_modifier):\n",
    "            origin = list(G.nodes)[np.random.choice(len(list(G.nodes)))]\n",
    "            first = list(oG.neighbors(origin))\n",
    "            neighborhood = []\n",
    "            for node in first:\n",
    "                neighborhood.append(node)\n",
    "                for nbr in list(oG.neighbors(node)):\n",
    "                    if nbr not in neighborhood:\n",
    "                        neighborhood.append(nbr)\n",
    "            for pair in itertools.product(neighborhood, neighborhood):\n",
    "                if pair[0] != pair[1]:\n",
    "                    G.add_edge(pair[0], pair[1]) \n",
    "\n",
    "def observe():\n",
    "    global G, assortativity, pos\n",
    "    plt.cla()\n",
    "    color_map = []\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['object'] == None:\n",
    "            color_map.append('grey')\n",
    "        elif G.nodes[node]['object'].color == 0:\n",
    "            color_map.append('red')\n",
    "        else:\n",
    "            color_map.append('blue')\n",
    "    nx.draw(G, pos = pos, node_size=30, node_color= color_map, with_labels=False)\n",
    "\n",
    "\n",
    "def update():\n",
    "    global G, assortativity, vacancies, xz_results, sch_results\n",
    "    candidate_nodes = []\n",
    "    for n in G.nodes:\n",
    "        if G.nodes[n]['object'] != None:\n",
    "            if G.nodes[n]['object'].tolerance_threshold == None:\n",
    "                candidate_nodes.append(n)\n",
    "            elif payoff(n,n) == 0:\n",
    "                candidate_nodes.append(n)\n",
    "    if len(candidate_nodes) == 0:\n",
    "        print(\"No more candidate nodes.\")\n",
    "        return None\n",
    "    node_a = candidate_nodes[np.random.choice(len(candidate_nodes))]\n",
    "    object_a = G.nodes[node_a]['object']\n",
    "    if object_a == None:\n",
    "        return None\n",
    "    candidate_vacancies = []\n",
    "    if object_a.tolerance_threshold == None:\n",
    "        candidate_vacancies_probabilities = non_guttman_transfer_probabilities(node_a, vacancies)\n",
    "        node_b = vacancies[np.random.choice(len(vacancies), p=candidate_vacancies_probabilities)]\n",
    "    else:\n",
    "        for v in vacancies:\n",
    "            if payoff(node_a,v) == 1:\n",
    "                candidate_vacancies.append(v)\n",
    "        if len(candidate_vacancies) == 0:\n",
    "            return None\n",
    "        node_b = candidate_vacancies[np.random.choice(len(candidate_vacancies))]\n",
    "    G.nodes[node_a]['object'] = None\n",
    "    G.nodes[node_a]['color'] = 2\n",
    "    G.nodes[node_b]['object'] = object_a\n",
    "    G.nodes[node_b]['color'] = object_a.color\n",
    "    vacancies.remove(node_b)\n",
    "    vacancies.append(node_a)\n",
    "\n",
    "def simulate():\n",
    "    global G, assortativity, xz_results, sch_results, result\n",
    "    iters = 1\n",
    "    excess_housing_fraction = 0.15\n",
    "    results = []\n",
    "    n=3\n",
    "    for k in range(iters):\n",
    "        method = \"schelling\"\n",
    "        topology_modifier = 0\n",
    "        initialize(topology_modifier = topology_modifier, excess_housing=0.15, method=method)\n",
    "        result = Result()\n",
    "        result.parameters = [f\"Topology Modifier: {topology_modifier}\", f\"Excess Housing Fraction: {excess_housing_fraction}\", f\"Method: {method}\"]\n",
    "        update_result()\n",
    "        for j in range(400):\n",
    "            update()\n",
    "            update_result()\n",
    "        result.graph = G\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "pycxsimulator.GUI().start([initialize,observe,update])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_entropy(prob_arr):\n",
    "    log_arr = np.array([np.log2(x) for x in prob_arr])\n",
    "    shannon = -1* sum([x*y for x,y in list(zip(prob_arr,log_arr))])\n",
    "    print(f\"Shannon: {shannon}\")\n",
    "\n",
    "def discretize(x,bins=50):\n",
    "    div = bins/100\n",
    "    buckets = np.arange(0,1,1/bins)\n",
    "    if x == -1:\n",
    "        return -1\n",
    "    elif x == -2:\n",
    "        return -2\n",
    "    else:\n",
    "        for i in range(len(buckets)):\n",
    "            if x > buckets[i]:\n",
    "                discrete_x = int((i/div))\n",
    "        return discrete_x\n",
    "\n",
    "def process_array(array,xlabel,ylabel):\n",
    "    for d in array:\n",
    "        df = pd.DataFrame(d)\n",
    "        df = df.sort_values(by=0,ascending=False)\n",
    "        df['Pair'] = \"(\" + df[0].astype(str) + \", \" + df[1].astype(str) + \")\"\n",
    "        probabilities = []\n",
    "        sorted_symbols = pd.DataFrame([str(sorted((x[1][0],x[1][1]))) for x in df.iterrows()])\n",
    "        for symbol in set(sorted_symbols[0]):\n",
    "            relative_freq = sorted_symbols[0].value_counts()[symbol]/len(sorted_symbols[0])\n",
    "            probabilities.append(relative_freq)\n",
    "        measure_entropy(probabilities)\n",
    "        df = df.groupby([0,1]).count().reset_index()\n",
    "        df['Pair'] = df['Pair'].apply(lambda x: np.log(x))\n",
    "        df = df.pivot_table(index=0,columns=1,values='Pair')\n",
    "        #df = df.fillna(0)\n",
    "        sns.heatmap(df,cmap='rocket_r',square=True).invert_yaxis()\n",
    "        plt.xlabel(f\"{ylabel}\")\n",
    "        plt.ylabel(f\"{xlabel}\")\n",
    "        plt.show()\n",
    "        #sns.heatmap(df.corr(),cmap='Spectral_r',square=True).invert_yaxis()\n",
    "        #plt.xlabel(f\"{ylabel}\")\n",
    "        #plt.ylabel(f\"{ylabel}\")\n",
    "        #lt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon: 5.502538035620577\n",
      "None\n",
      "Shannon: 7.235656295038293\n",
      "None\n",
      "Shannon: 8.149931862032213\n",
      "None\n",
      "Shannon: 8.743942055422098\n",
      "None\n",
      "Shannon: 9.11363549110648\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "array = [[],[],[],[],[]]\n",
    "for i in range(5):\n",
    "    for _ in range(100):\n",
    "        initialize(topology_modifier=i*32)\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node]['object'] != None:\n",
    "                if G.nodes[node]['object'].tolerance_threshold != None:\n",
    "                    tol = G.nodes[node]['object'].tolerance_threshold\n",
    "                else:\n",
    "                    tol = -1\n",
    "            else:\n",
    "                tol = -2\n",
    "            degree = G.degree(node)\n",
    "            array[i].append((tol,degree))\n",
    "                \n",
    "process_array('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon: 7.639446973194153\n",
      "Shannon: 7.645915273928806\n",
      "Shannon: 7.6335080539529505\n",
      "Shannon: 7.641220559686054\n",
      "Shannon: 7.640025487288715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "         \n",
    "array = [[],[],[],[],[]]\n",
    "for i in range(5):\n",
    "    for _ in range(100):\n",
    "        initialize(topology_modifier=i*32)\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node]['object'] != None:\n",
    "                if G.nodes[node]['object'].tolerance_threshold != None:\n",
    "                    tol = G.nodes[node]['object'].tolerance_threshold\n",
    "                else:\n",
    "                    tol = -1\n",
    "            else:\n",
    "                tol = -2\n",
    "            tol = discretize(tol,bins=25)\n",
    "            node_color = G.nodes[node]['color']\n",
    "            node_degree = G.degree(node)\n",
    "            for nbr in G.neighbors(node):\n",
    "                if G.nodes[nbr]['color'] != G.nodes[node]['color']:\n",
    "                    if G.nodes[nbr]['object'] != None:\n",
    "                        if G.nodes[nbr]['object'].tolerance_threshold != None:\n",
    "                            nbr_tol = G.nodes[nbr]['object'].tolerance_threshold\n",
    "                        else:\n",
    "                            nbr_tol = -1\n",
    "                    else:\n",
    "                        nbr_tol = -2\n",
    "                    nbr_tol = discretize(nbr_tol,bins=25)\n",
    "                    nbr_color = G.nodes[nbr]['color']\n",
    "                    nbr_degree = G.degree(nbr)\n",
    "                    array[i].append([(tol),(nbr_tol)])\n",
    "\n",
    "process_array(array,'Node Tolerance','Neighbor Tolerance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(0,2),(0,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.degree(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x27125b59700>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.neighbors(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mset\u001b[39m([G\u001b[39m.\u001b[39mnodes[node][\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m G\u001b[39m.\u001b[39mnodes])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
